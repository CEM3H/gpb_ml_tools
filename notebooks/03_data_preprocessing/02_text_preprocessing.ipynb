{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
       "\n",
       "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPB –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.\n",
       "\n",
       "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import sys\n",
       "sys.path.append('../../')\n",
       "\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from core.data.preprocessing import TextPreprocessor"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞\n",
       "data = pd.DataFrame({\n",
       "    'id': [1, 2, 3, 4, 5],\n",
       "    'text': [\n",
       "        'This is a sample text with some numbers 123 and special characters !@#',\n",
       "        'Another example of text with UPPERCASE and lowercase words',\n",
       "        'Text with multiple   spaces and\\nnewlines',\n",
       "        'Text with HTML tags <p>Hello</p> and URLs https://example.com',\n",
       "        'Text with emojis üòä and mentions @user'\n",
       "    ]\n",
       "})\n",
       "\n",
       "print(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
       "print(data)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞\n",
       "preprocessor = TextPreprocessor()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
       "cleaned_text = preprocessor.clean_text(\n",
       "    data['text'],\n",
       "    remove_numbers=True,\n",
       "    remove_special_chars=True,\n",
       "    remove_extra_spaces=True,\n",
       "    remove_html=True,\n",
       "    remove_urls=True,\n",
       "    remove_mentions=True,\n",
       "    remove_emojis=True\n",
       ")\n",
       "\n",
       "print(\"–¢–µ–∫—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:\")\n",
       "print(cleaned_text)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
       "tokens = preprocessor.tokenize(\n",
       "    cleaned_text,\n",
       "    lowercase=True,\n",
       "    remove_punctuation=True\n",
       ")\n",
       "\n",
       "print(\"–¢–æ–∫–µ–Ω—ã:\")\n",
       "print(tokens)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
       "filtered_tokens = preprocessor.remove_stopwords(\n",
       "    tokens,\n",
       "    language='english'\n",
       ")\n",
       "\n",
       "print(\"–¢–æ–∫–µ–Ω—ã –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤:\")\n",
       "print(filtered_tokens)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –°—Ç–µ–º–º–∏–Ω–≥ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –°—Ç–µ–º–º–∏–Ω–≥\n",
       "stemmed_tokens = preprocessor.stem(\n",
       "    filtered_tokens,\n",
       "    language='english'\n",
       ")\n",
       "\n",
       "print(\"–¢–æ–∫–µ–Ω—ã –ø–æ—Å–ª–µ —Å—Ç–µ–º–º–∏–Ω–≥–∞:\")\n",
       "print(stemmed_tokens)\n",
       "\n",
       "# –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
       "lemmatized_tokens = preprocessor.lemmatize(\n",
       "    filtered_tokens,\n",
       "    language='english'\n",
       ")\n",
       "\n",
       "print(\"–¢–æ–∫–µ–Ω—ã –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏:\")\n",
       "print(lemmatized_tokens)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
       "tfidf_vectors = preprocessor.tfidf_vectorize(\n",
       "    lemmatized_tokens,\n",
       "    max_features=1000\n",
       ")\n",
       "\n",
       "print(\"TF-IDF –≤–µ–∫—Ç–æ—Ä—ã:\")\n",
       "print(tfidf_vectors.toarray())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞\n",
       "preprocessor.save('models/text_preprocessor.pkl')\n",
       "print(\"–¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }